<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Face Recognition</title>
  <script defer src="face-api.min.js"></script>
  <style>
    body {
      margin: 0;
      padding: 0;
      width: 100vw;
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
    }

    canvas {
      position: absolute;
    }
  </style>
</head>
<body>
  <video id="video" width="720" height="560" autoplay muted></video>
  <script type="module">
    import { initializeApp } from "https://www.gstatic.com/firebasejs/10.10.0/firebase-app.js";
    import { getAnalytics } from "https://www.gstatic.com/firebasejs/10.10.0/firebase-analytics.js";
    import { getDatabase, ref, set } from "https://www.gstatic.com/firebasejs/10.10.0/firebase-database.js";

    // Your Firebase configuration
    const firebaseConfig = {
      apiKey: "AIzaSyBBmlyzEPmB63RfgInLT4N6yN-yUofkb74",
      authDomain: "emotion-f71ff.firebaseapp.com",
      databaseURL: "https://emotion-f71ff-default-rtdb.firebaseio.com",
      projectId: "emotion-f71ff",
      storageBucket: "emotion-f71ff.appspot.com",
      messagingSenderId: "216139511260",
      appId: "1:216139511260:web:f1616b0b787c0302248b19",
      measurementId: "G-YVFD5V7HEZ",
      databaseURL: "https://emotion-f71ff-default-rtdb.firebaseio.com"
    };

    // Initialize Firebase
    const app = initializeApp(firebaseConfig);
    const analytics = getAnalytics(app);
    const db = getDatabase();

    // Rest of your code
    const video = document.getElementById('video');

    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
      faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
      faceapi.nets.faceRecognitionNet.loadFromUri('/models'),
      faceapi.nets.faceExpressionNet.loadFromUri('/models')
    ]).then(startVideo);

    function startVideo() {
      navigator.getUserMedia(
        { video: {} },
        stream => video.srcObject = stream,
        err => console.error(err)
      );
    }

    video.addEventListener('play', () => {
      const canvas = faceapi.createCanvasFromMedia(video);
      document.body.append(canvas);
      const displaySize = { width: video.width, height: video.height };
      faceapi.matchDimensions(canvas, displaySize);
      setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();
        const resizedDetections = faceapi.resizeResults(detections, displaySize);
        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
        faceapi.draw.drawDetections(canvas, resizedDetections);
        faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
        faceapi.draw.drawFaceExpressions(canvas, resizedDetections);

        // Get detected emotions
        // Get detected emotions
        const emotions = resizedDetections.map(detection => detection.expressions);
        const highestEmotion = emotions.reduce((acc, cur) => {
          const maxEmotion = Object.keys(cur).reduce((a, b) => cur[a] > cur[b] ? a : b);
          return { ...acc, [maxEmotion]: cur[maxEmotion] };
        }, {});

        // Send highest emotion data to Firebase Realtime Database
        try {
          await set(ref(db, 'emotions'), highestEmotion);
          console.log("Emotion data added to Realtime Database");
        } catch (e) {
          console.error("Error adding data to Realtime Database: ", e);
        }

      }, 300);
    });
  </script>
</body>
</html>