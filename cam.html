<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Face Recognition</title>
  <!-- Load face-api.js library -->
  <script defer src="./face-api.min.js"></script>
  <!-- Link to external CSS file -->
  <link rel="stylesheet" href="./assets/styles.css">
  <!-- Firebase SDK -->
  <script type="module">
    // Import the functions you need from the SDKs you need
    import { initializeApp } from "https://www.gstatic.com/firebasejs/11.0.1/firebase-app.js";
    import { getDatabase, ref, set, push, get } from "https://www.gstatic.com/firebasejs/11.0.1/firebase-database.js";

    // Your web app's Firebase configuration
    const firebaseConfig = {
      apiKey: "AIzaSyAb2Y-eni-EwsMHB6p7s45SliloUXgyTe8",
      authDomain: "mimic-master-3b78d.firebaseapp.com",
      databaseURL: "https://mimic-master-3b78d-default-rtdb.firebaseio.com",
      projectId: "mimic-master-3b78d",
      storageBucket: "mimic-master-3b78d.appspot.com",
      messagingSenderId: "1067863388568",
      appId: "1:1067863388568:web:679a6f748f589319ccbbed",
      measurementId: "G-1VE53HXVFP"
    };

    // Initialize Firebase
    const app = initializeApp(firebaseConfig);
    const db = getDatabase(app);

    // Declare the videoStream variable
    let videoStream;

    // Get references to HTML elements
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const expressionElement = document.getElementById('expression');
    const counterElement = document.getElementById('counter');
    const loadingOverlay = document.getElementById('loading-overlay');
    const captureDisplay = document.getElementById('capture-display');
    const capturedImage = document.getElementById('captured-image');
    const capturedText = document.getElementById('captured-text');
    const container = document.getElementById('container');
    const gameOverDisplay = document.getElementById('game-over');
    const totalScoreDisplay = document.getElementById('total-score');
    let counter = 5;
    let totalScore = 0;
    const username = localStorage.getItem('username');
    let detectionInterval;

    // List of expressions to be displayed with corresponding emojis
    const expressions = [
      { name: 'happy', emoji: '😊' },
      { name: 'angry', emoji: '😠' },
      { name: 'sad', emoji: '😢' },
      { name: 'neutral', emoji: '😐' },
      { name: 'surprised', emoji: '😲' }
    ];

    // Load face-api.js models
    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
      await faceapi.nets.faceRecognitionNet.loadFromUri('./models');
      await faceapi.nets.faceExpressionNet.loadFromUri('./models');
    }

    // Start the webcam video feed
    function startVideo() {
      navigator.mediaDevices.getUserMedia({ video: {} })
        .then(stream => {
          video.srcObject = stream;
          videoStream = stream; // Assign the stream to the videoStream variable
        })
        .catch(err => console.error(err));
    }

    // Shuffle the array of expressions
    function shuffleArray(array) {
      for (let i = array.length - 1; i > 0; i--) {
        const j = Math.floor(Math.random() * (i + 1));
        [array[i], array[j]] = [array[j], array[i]];
      }
    }

    // Start the game by displaying expressions one by one
    function startGame() {
      shuffleArray(expressions);
      let currentExpressionIndex = 0;

      function showNextExpression() {
        if (currentExpressionIndex < expressions.length) {
          const currentExpression = expressions[currentExpressionIndex];
          expressionElement.innerHTML = `<h2>Make a ${currentExpression.name} expression! ${currentExpression.emoji}</h2>`;
          counter = 5;
          counterElement.textContent = counter;

          const interval = setInterval(() => {
            if (counter > 0) {
              counter--;
              counterElement.textContent = counter;
            } else {
              clearInterval(interval);
              captureAndShowImage(currentExpression);
              currentExpressionIndex++;
              setTimeout(() => {
                captureDisplay.classList.add('fade-out');
                setTimeout(() => {
                  captureDisplay.classList.remove('fade-out');
                  captureDisplay.style.display = 'none';
                  container.style.display = 'flex';
                  showNextExpression();
                }, 1000); // Duration of the fade-out animation
              }, 2000); // Show the captured image for 2 seconds before transitioning
            }
          }, 1000);
        } else {
          expressionElement.innerHTML = '<strong>Game Over!</strong>';
          stopDetection();
          saveScore(username, totalScore);
          setUserPlayedState(username, true);
          totalScoreDisplay.innerHTML = `<p>Total Score: ${totalScore.toFixed(2)}</p>`;
            gameOverDisplay.style.display = 'flex';
            gameOverDisplay.style.flexDirection = 'column';
        }
      }

      showNextExpression();
    }

    // Capture the current frame from the video and display it on the canvas
    async function captureAndShowImage(expression) {
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      faceapi.matchDimensions(canvas, displaySize);

      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();
      const resizedDetections = faceapi.resizeResults(detections, displaySize);

      const context = canvas.getContext('2d');
      context.clearRect(0, 0, canvas.width, canvas.height);

      // Save the current context state
      context.save();
      context.translate(canvas.width, 0);
      context.scale(-1, 1); // Mirror the canvas

      // Draw the current frame from the video without landmarks
      context.drawImage(video, 0, 0, canvas.width, canvas.height);

      // Restore the context to its original state
      context.restore();

      // Convert the canvas to an image and display it
      const dataUrl = canvas.toDataURL('image/png');
      capturedImage.src = dataUrl;
      const expressionScore = detections.length > 0 ? (detections[0].expressions[expression.name] || 0) : 0;
      capturedText.innerHTML = `Your ${expression.name} expression ${expression.emoji}<br>Score: ${expressionScore.toFixed(2)}`;
      captureDisplay.style.display = 'block';
      container.style.display = 'none';

      // Add the score to the total score
      totalScore += expressionScore;

      // Log the captured emotion and score
      console.log(`Captured image for expression: ${expression.name}, Score: ${expressionScore}, Total Score: ${totalScore}`);
    }

    // Continuously detect faces and draw landmarks on the canvas
    async function detectFaces() {
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      faceapi.matchDimensions(canvas, displaySize);

      detectionInterval = setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();
        const resizedDetections = faceapi.resizeResults(detections, displaySize);

        const context = canvas.getContext('2d');
        context.clearRect(0, 0, canvas.width, canvas.height);

        // Save the current context state
        context.save();
        context.translate(canvas.width, 0);
        context.scale(-1, 1); // Mirror the canvas

        // Draw the face landmarks
        faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

        // Restore the context to its original state
        context.restore();
      }, 100);
    }

    // Stop face detection and hide the canvas, video, and camera
    function stopDetection() {
      clearInterval(detectionInterval);
      if (video.srcObject) {
        video.srcObject.getTracks().forEach(track => track.stop());
      }
      canvas.remove();
      video.remove();
      expressionElement.remove();
      counterElement.remove();
      gameOverDisplay.style.display = 'flex';
    }

    // Save the score to Realtime Database
    async function saveScore(username, score) {
      const scoresRef = ref(db, 'scores');
      await push(scoresRef, {
        username: username,
        score: score,
        timestamp: Date.now()
      });
    }

    // Set the user played state for the current user in Firebase
    async function setUserPlayedState(username, hasPlayed) {
      const userPlayedRef = ref(db, `userPlayed/${username}`);
      await set(userPlayedRef, { hasPlayed: hasPlayed });
    }

    // Check if the user has already played the game
    async function hasUserPlayed(username) {
      const userPlayedRef = ref(db, `userPlayed/${username}`);
      const snapshot = await get(userPlayedRef);
      const userPlayed = snapshot.val();
      return userPlayed && userPlayed.hasPlayed;
    }

    // Initialize the application
    document.addEventListener('DOMContentLoaded', async () => {
      const userPlayed = await hasUserPlayed(username);
      const gameStateRef = ref(db, 'gameState/state');
      const gameStateSnapshot = await get(gameStateRef);
      const gameState = gameStateSnapshot.val();

      if (userPlayed) {
        alert('You have already played the game.');
        return;
      }

      if (gameState && gameState.isGameOpen) {
        await loadModels();
        startVideo();
        video.addEventListener('loadedmetadata', () => {
          // Hide the loading overlay once models are loaded and video metadata is ready
          loadingOverlay.style.display = 'none';
          startGame();
          detectFaces();
        });
      } else {
        alert('The game is currently closed.');
      }
    });
  </script>
</head>
<body>
  <div id="container">
    <!-- Loading overlay -->
    <div id="loading-overlay">
      <div class="spinner"></div>
      <p>Please wait, model is loading...</p>
    </div>
    <!-- Video element to display webcam feed -->
    <video id="video" autoplay muted></video>
    <!-- Canvas element to draw face landmarks and captured images -->
    <canvas id="canvas"></canvas>
    <!-- Display area for current expression and counter -->
    <div id="emotion-display">
      <p id="expression"><strong>Make an expression!</strong></p>
      <p id="counter">5</p>
    </div>
  </div>
  <!-- Container to display captured image and expression -->
  <div id="capture-display" class="container" style="display: none;">
    <img id="captured-image" src="" alt="Captured Expression">
    <div id="captured-text" class="text"></div>
  </div>
  <!-- Game Over message -->
  <div id="game-over" class="container" style="display: none;">
    <div id="total-score"></div>
    <p>Game Over!</p>
  </div>
</body>
</html>