<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Face Recognition</title>
  <!-- Load face-api.js library -->
  <script defer src="./face-api.min.js"></script>
  <!-- Link to external CSS file -->
  <link rel="stylesheet" href="./assets/styles.css">
</head>
<body>
  <div id="container">
    <!-- Loading overlay -->
    <div id="loading-overlay">
      <div class="spinner"></div>
      <p>Please wait, model is loading...</p>
    </div>
    <!-- Video element to display webcam feed -->
    <video id="video" autoplay muted></video>
    <!-- Canvas element to draw face landmarks and captured images -->
    <canvas id="canvas"></canvas>
    <!-- Display area for current expression and counter -->
    <div id="emotion-display">
      <p id="expression">Make an expression!</p>
      <p id="counter">5</p>
    </div>
  </div>
  <!-- Container to display captured image and expression -->
  <div id="capture-display" class="container" style="display: none;">
    <img id="captured-image" src="" alt="Captured Expression">
    <div id="captured-text" class="text"></div>
  </div>
  <!-- Game Over message -->
  <div id="game-over" class="container" style="display: none;">
    <p>Game Over!</p>
  </div>
  <script type="module">
    // Get references to HTML elements
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const expressionElement = document.getElementById('expression');
    const counterElement = document.getElementById('counter');
    const loadingOverlay = document.getElementById('loading-overlay');
    const captureDisplay = document.getElementById('capture-display');
    const capturedImage = document.getElementById('captured-image');
    const capturedText = document.getElementById('captured-text');
    const container = document.getElementById('container');
    const gameOverDisplay = document.getElementById('game-over');
    let counter = 5;
    let totalScore = 0;
    const username = localStorage.getItem('username');
    let detectionInterval;

    // List of expressions to be displayed
    const expressions = ['happy', 'angry', 'sad', 'neutral', 'surprised'];

    // Load face-api.js models
    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
      await faceapi.nets.faceRecognitionNet.loadFromUri('./models');
      await faceapi.nets.faceExpressionNet.loadFromUri('./models');
    }

    // Start the webcam video feed
    function startVideo() {
      navigator.mediaDevices.getUserMedia({ video: {} })
        .then(stream => {
          video.srcObject = stream;
          videoStream = stream;
        })
        .catch(err => console.error(err));
    }

    // Shuffle the array of expressions
    function shuffleArray(array) {
      for (let i = array.length - 1; i > 0; i--) {
        const j = Math.floor(Math.random() * (i + 1));
        [array[i], array[j]] = [array[j], array[i]];
      }
    }

    // Start the game by displaying expressions one by one
    function startGame() {
      shuffleArray(expressions);
      let currentExpressionIndex = 0;

      function showNextExpression() {
        if (currentExpressionIndex < expressions.length) {
          const currentExpression = expressions[currentExpressionIndex];
          expressionElement.textContent = `Make a ${currentExpression} expression!`;
          counter = 5;
          counterElement.textContent = counter;

          const interval = setInterval(() => {
            if (counter > 0) {
              counter--;
              counterElement.textContent = counter;
            } else {
              clearInterval(interval);
              captureAndShowImage(currentExpression);
              currentExpressionIndex++;
              setTimeout(() => {
                captureDisplay.classList.add('fade-out');
                setTimeout(() => {
                  captureDisplay.classList.remove('fade-out');
                  captureDisplay.style.display = 'none';
                  container.style.display = 'flex';
                  showNextExpression();
                }, 1000); // Duration of the fade-out animation
              }, 2000); // Show the captured image for 2 seconds before transitioning
            }
          }, 1000);
        } else {
          expressionElement.textContent = 'Game Over!';
          saveScore(username, totalScore);
          stopDetection();
        }
      }

      showNextExpression();
    }

    // Capture the current frame from the video and display it on the canvas
    async function captureAndShowImage(expression) {
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      faceapi.matchDimensions(canvas, displaySize);

      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();
      const resizedDetections = faceapi.resizeResults(detections, displaySize);

      const context = canvas.getContext('2d');
      context.clearRect(0, 0, canvas.width, canvas.height);

      // Save the current context state
      context.save();
      context.translate(canvas.width, 0);
      context.scale(-1, 1); // Mirror the canvas

      // Draw the current frame from the video without landmarks
      context.drawImage(video, 0, 0, canvas.width, canvas.height);

      // Restore the context to its original state
      context.restore();

      // Convert the canvas to an image and display it
      const dataUrl = canvas.toDataURL('image/png');
      capturedImage.src = dataUrl;
      capturedText.textContent = `Your ${expression} expression`;
      captureDisplay.style.display = 'block';
      container.style.display = 'none';

      // Get the score for the current expression
      let expressionScore = 0;
      if (detections.length > 0) {
        const expressions = detections[0].expressions;
        expressionScore = expressions[expression] || 0;
      }

      // Add the score to the total score
      totalScore += expressionScore;

      // Log the captured emotion and score
      console.log(`Captured image for expression: ${expression}, Score: ${expressionScore}, Total Score: ${totalScore}`);
    }

    // Continuously detect faces and draw landmarks on the canvas
    async function detectFaces() {
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      faceapi.matchDimensions(canvas, displaySize);

      detectionInterval = setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();
        const resizedDetections = faceapi.resizeResults(detections, displaySize);

        const context = canvas.getContext('2d');
        context.clearRect(0, 0, canvas.width, canvas.height);

        // Save the current context state
        context.save();
        context.translate(canvas.width, 0);
        context.scale(-1, 1); // Mirror the canvas

        // Draw the face landmarks
        faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

        // Restore the context to its original state
        context.restore();
      }, 100);
    }

    // Stop face detection and hide the canvas, video, and camera
    function stopDetection() {
      clearInterval(detectionInterval);
      if (video.srcObject) {
        video.srcObject.getTracks().forEach(track => track.stop());
      }
      canvas.remove();
      video.remove();
      expressionElement.remove();
      counterElement.remove();
      gameOverDisplay.style.display = 'flex';
    }

    // Save the score to GitHub
    async function saveScore(username, score) {
      const token = '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'; // Replace with your GitHub token
      const repo = 'dharanidharatdd/iot-workshop'; // Replace with your GitHub username and repository name
      const path = 'assets/leaderboard.json';
      const apiUrl = `https://api.github.com/repos/${repo}/contents/${path}`;

      // Fetch the current leaderboard data
      const response = await fetch(apiUrl, {
        headers: {
          'Authorization': `token ${token}`,
          'Accept': 'application/vnd.github.v3+json'
        }
      });
      const data = await response.json();
      const content = atob(data.content);
      const players = JSON.parse(content);

      // Add the new score
      players.push({ name: username, score: score });

      // Update the leaderboard data
      const updatedContent = btoa(JSON.stringify(players, null, 2));
      await fetch(apiUrl, {
        method: 'PUT',
        headers: {
          'Authorization': `token ${token}`,
          'Accept': 'application/vnd.github.v3+json'
        },
        body: JSON.stringify({
          message: 'Update leaderboard',
          content: updatedContent,
          sha: data.sha
        })
      });
    }

    // Initialize the application
    document.addEventListener('DOMContentLoaded', async () => {
      await loadModels();
      startVideo();
      video.addEventListener('loadedmetadata', () => {
        // Hide the loading overlay once models are loaded and video metadata is ready
        loadingOverlay.style.display = 'none';
        startGame();
        detectFaces();
      });
    });
  </script>
</body>
</html>